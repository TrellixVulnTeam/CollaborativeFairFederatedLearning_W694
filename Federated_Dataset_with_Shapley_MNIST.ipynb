{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Tags",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Federated Dataset with Shapley MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eef7da1fd24545f7b7dee979e646a3f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8aa9836d9f274803b94931f34fbdb5a1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_18d92eec7e4a409e8cf6b05d3445972d",
              "IPY_MODEL_2cf761a67ba247e28a54ee5ae463a847"
            ]
          }
        },
        "8aa9836d9f274803b94931f34fbdb5a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "18d92eec7e4a409e8cf6b05d3445972d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_add2406d2ee5423e8cf5df5acc453b33",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d87ddfb514164dfc8b87eddf66dab4a8"
          }
        },
        "2cf761a67ba247e28a54ee5ae463a847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6f753a57290b49e1ace3fbca13143a1c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9920512/? [00:06&lt;00:00, 1646590.37it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad77178711b745bb8ad865512e3f8bb6"
          }
        },
        "add2406d2ee5423e8cf5df5acc453b33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d87ddfb514164dfc8b87eddf66dab4a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f753a57290b49e1ace3fbca13143a1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad77178711b745bb8ad865512e3f8bb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a5f43b7db0324260a8906571e4fd4ae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a5c95605762c43369efd9014eecf6015",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6183d7d833f94510b3afbbdea0945187",
              "IPY_MODEL_6cac45805ae14b9a958dde655285b374"
            ]
          }
        },
        "a5c95605762c43369efd9014eecf6015": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6183d7d833f94510b3afbbdea0945187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_96f9ec6fb5884ae2998f48383b3b335d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d5a0d65c82b4f838b32f2c8ee4828f8"
          }
        },
        "6cac45805ae14b9a958dde655285b374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ea88884ab90c466bb932d8a6188c850c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 32768/? [00:00&lt;00:00, 48000.31it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_93f755210bf34b38989bc0b2841510b1"
          }
        },
        "96f9ec6fb5884ae2998f48383b3b335d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d5a0d65c82b4f838b32f2c8ee4828f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea88884ab90c466bb932d8a6188c850c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "93f755210bf34b38989bc0b2841510b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "af5c9c9d50d24dae86d90e9a7c431d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cd18d4974dd54b219e43c7e93d904e0d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dd5cabc1a3c145d0867a8d242e686b18",
              "IPY_MODEL_e12c3bc553cf4d238cf33175d1dadf31"
            ]
          }
        },
        "cd18d4974dd54b219e43c7e93d904e0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd5cabc1a3c145d0867a8d242e686b18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6e4d39863e454f1e83448f87c5bbbc66",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_056be4dd6527493eb4990a46b59e238e"
          }
        },
        "e12c3bc553cf4d238cf33175d1dadf31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c084baef6de9469cb0a4bf4b967b11c5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1654784/? [00:02&lt;00:00, 570616.37it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_28c4474562a04f938d10569b2344f84a"
          }
        },
        "6e4d39863e454f1e83448f87c5bbbc66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "056be4dd6527493eb4990a46b59e238e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c084baef6de9469cb0a4bf4b967b11c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "28c4474562a04f938d10569b2344f84a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b0a7ac7bc3b540efbfe6f581317601be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a281a6f24c4546f8a97aa6b78865d2d0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d166957e3ff9442a9ce0df3dc1f51b2b",
              "IPY_MODEL_2eb0ec35942245b0b724301d24204699"
            ]
          }
        },
        "a281a6f24c4546f8a97aa6b78865d2d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d166957e3ff9442a9ce0df3dc1f51b2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_02f01bc1bca44a24bea86c9784e5a82d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f7beb8e03fc4481942427547dff92eb"
          }
        },
        "2eb0ec35942245b0b724301d24204699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f94c848b51074b8485fc35fe66c61440",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8192/? [00:00&lt;00:00, 9479.91it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b772bb983b3344a587ecf6be04f06dd5"
          }
        },
        "02f01bc1bca44a24bea86c9784e5a82d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f7beb8e03fc4481942427547dff92eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f94c848b51074b8485fc35fe66c61440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b772bb983b3344a587ecf6be04f06dd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XinyiYS/FairAndPrivateFederatedLearning/blob/master/Federated_Dataset_with_Shapley_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_V6KLvuauea_",
        "colab_type": "text"
      },
      "source": [
        "# Federated Dataset with Shapley.ipynb\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osxkFljzvBDW",
        "colab_type": "code",
        "outputId": "e3b0d1ba-5d36-4f15-d89e-dff1208afcb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install 'syft[udacity]'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting syft[udacity]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8b/dc9a253392908d480322466832d618d85cdb1b66a1781604cf1064b50c32/syft-0.2.4-py3-none-any.whl (341kB)\n",
            "\r\u001b[K     |█                               | 10kB 27.0MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 34.7MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30kB 38.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 40kB 40.2MB/s eta 0:00:01\r\u001b[K     |████▉                           | 51kB 42.7MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 61kB 45.0MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 71kB 44.6MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 81kB 44.6MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 92kB 45.6MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 102kB 44.1MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 112kB 44.1MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 122kB 44.1MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 133kB 44.1MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 143kB 44.1MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 153kB 44.1MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 163kB 44.1MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 174kB 44.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 184kB 44.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 194kB 44.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 204kB 44.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 215kB 44.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 225kB 44.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 235kB 44.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 245kB 44.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 256kB 44.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 266kB 44.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 276kB 44.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 286kB 44.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 296kB 44.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 307kB 44.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 317kB 44.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 327kB 44.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 337kB 44.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 348kB 44.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask~=1.1.1 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (1.1.1)\n",
            "Requirement already satisfied: msgpack~=1.0.0 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (1.0.0)\n",
            "Collecting flask-socketio~=4.2.1\n",
            "  Downloading https://files.pythonhosted.org/packages/66/44/edc4715af85671b943c18ac8345d0207972284a0cd630126ff5251faa08b/Flask_SocketIO-4.2.1-py2.py3-none-any.whl\n",
            "Collecting requests~=2.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.9MB/s \n",
            "\u001b[?25hCollecting Pillow~=6.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/fd/bbbc569f98f47813c50a116b539d97b3b17a86ac7a309f83b2022d26caf2/Pillow-6.2.2-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 56.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tornado==4.5.3 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (4.5.3)\n",
            "Collecting websocket-client~=0.57.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 55.7MB/s \n",
            "\u001b[?25hCollecting phe~=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/32/0e/568e97b014eb14e794a1258a341361e9da351dc6240c63b89e1541e3341c/phe-1.4.0.tar.gz\n",
            "Requirement already satisfied: tblib~=1.6.0 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (1.6.0)\n",
            "Requirement already satisfied: torchvision~=0.5.0 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (0.5.0)\n",
            "Requirement already satisfied: scipy~=1.4.1 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (1.4.1)\n",
            "Collecting websockets~=8.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/d9/856af84843912e2853b1b6e898ac8b802989fcf9ecf8e8445a1da263bf3b/websockets-8.1-cp36-cp36m-manylinux2010_x86_64.whl (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.7MB/s \n",
            "\u001b[?25hCollecting syft-proto~=0.2.5.a1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/ab/849e6ef6c0e7af1a2a1d7a18f478fa07cd2217ed63867ab101ad5abff302/syft_proto-0.2.5a1-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.18.1 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (1.18.2)\n",
            "Collecting lz4~=3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/81/011fef8766fb0ef681037ad6fee96168ee03a864464986cbaa23e5357704/lz4-3.0.2-cp36-cp36m-manylinux2010_x86_64.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 58.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch~=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (1.4.0)\n",
            "Collecting tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/be/a4c0af9fdc5e5cee28495460538acf2766382bd572e01d4847abc7608dba/tf_encrypted-0.5.9-py3-none-manylinux1_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 45.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask~=1.1.1->syft[udacity]) (2.11.1)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask~=1.1.1->syft[udacity]) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask~=1.1.1->syft[udacity]) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask~=1.1.1->syft[udacity]) (7.1.1)\n",
            "Collecting python-socketio>=4.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/cb/631c0b713daea3938e66d4c0923e88f3c0b57b026f860ea76e0337bc9c7a/python_socketio-4.5.1-py2.py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests~=2.22.0->syft[udacity]) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests~=2.22.0->syft[udacity]) (2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests~=2.22.0->syft[udacity]) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests~=2.22.0->syft[udacity]) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from websocket-client~=0.57.0->syft[udacity]) (1.12.0)\n",
            "Collecting protobuf>=3.11.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/02/5432412c162989260fab61fa65e0a490c1872739eb91a659896e4d554b26/protobuf-3.11.3-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 49.7MB/s \n",
            "\u001b[?25hCollecting tensorflow<2,>=1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/d9/fd234c7bf68638423fb8e7f44af7fcfce3bcaf416b51e6d902391e47ec43/tensorflow-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (110.5MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5MB 106kB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 53.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask~=1.1.1->syft[udacity]) (1.1.1)\n",
            "Collecting python-engineio>=3.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/aa/c975982df73c4bcd087732db14b05306e8a3f3f24596cc18647746539290/python_engineio-3.12.1-py2.py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.11.1->syft-proto~=0.2.5.a1->syft[udacity]) (46.1.3)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 38.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (0.34.2)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (3.2.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 50.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (0.9.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (1.27.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (3.2.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (2.10.0)\n",
            "Building wheels for collected packages: phe, pyyaml, gast\n",
            "  Building wheel for phe (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for phe: filename=phe-1.4.0-py2.py3-none-any.whl size=37362 sha256=9664a9c2e63eb59162ce091d087865c16c056b4e957d29c9dedc4dd1ea8fc9f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/dc/36/dcb6bf0f1b9907e7b710ace63e64d08e7022340909315fdea4\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44621 sha256=2ba37a96bc6ef02a23ee616b70dadc7c9fd48912e2d7006a6beefa1b3a5feaab\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=8c2979d4585ae5db3c75868aebf0114aa0a06be75b9f7d1146d5f1410670ff8e\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built phe pyyaml gast\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.21.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: python-engineio, python-socketio, flask-socketio, requests, Pillow, websocket-client, phe, websockets, protobuf, syft-proto, lz4, tensorboard, gast, tensorflow-estimator, tensorflow, pyyaml, tf-encrypted, syft\n",
            "  Found existing installation: requests 2.21.0\n",
            "    Uninstalling requests-2.21.0:\n",
            "      Successfully uninstalled requests-2.21.0\n",
            "  Found existing installation: Pillow 7.0.0\n",
            "    Uninstalling Pillow-7.0.0:\n",
            "      Successfully uninstalled Pillow-7.0.0\n",
            "  Found existing installation: protobuf 3.10.0\n",
            "    Uninstalling protobuf-3.10.0:\n",
            "      Successfully uninstalled protobuf-3.10.0\n",
            "  Found existing installation: tensorboard 2.2.0\n",
            "    Uninstalling tensorboard-2.2.0:\n",
            "      Successfully uninstalled tensorboard-2.2.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
            "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
            "  Found existing installation: tensorflow 2.2.0rc2\n",
            "    Uninstalling tensorflow-2.2.0rc2:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc2\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed Pillow-6.2.2 flask-socketio-4.2.1 gast-0.2.2 lz4-3.0.2 phe-1.4.0 protobuf-3.11.3 python-engineio-3.12.1 python-socketio-4.5.1 pyyaml-5.3.1 requests-2.22.0 syft-0.2.4 syft-proto-0.2.5a1 tensorboard-1.15.0 tensorflow-1.15.2 tensorflow-estimator-1.15.1 tf-encrypted-0.5.9 websocket-client-0.57.0 websockets-8.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "google",
                  "requests"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpsepMYvATV7",
        "colab_type": "code",
        "outputId": "58fc5ba8-9dd0-46c7-9b80-6e5facffa81d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLB-g-bPuebB",
        "colab_type": "code",
        "outputId": "f3dc95cf-c3b1-4ccb-e3a4-0fded6041a71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "import random\n",
        "from itertools import permutations\n",
        "import copy\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import syft as sy  # <-- NEW: import the Pysyft library\n",
        "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
        "\n",
        "\n",
        "# bob = sy.VirtualWorker(hook, id=\"bob\")  # <-- NEW: define remote worker bob\n",
        "# alice = sy.VirtualWorker(hook, id=\"alice\")  # <-- NEW: and alice"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.2.so'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN73GJ-eybxh",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 10 #@param\n",
        "        self.test_batch_size = 5000 #@param\n",
        "        self.epochs =  5#@param\n",
        "        self.lr = 0.15 #@param\n",
        "        self.momentum = 0.5\n",
        "        self.no_cuda = False\n",
        "        self.seed = 1\n",
        "        self.log_interval = 150 #@param\n",
        "        self.save_model = False\n",
        "        self.num_workers = 3#@param\n",
        "        self.workers =  [sy.VirtualWorker(hook, id=str(i)) for i in range(self.num_workers) ]\n",
        "\n",
        "\n",
        "args = Arguments()\n",
        "\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg2C19D6ywFY",
        "colab_type": "code",
        "outputId": "56213614-8bae-4cb7-dccd-de99c6ef23c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420,
          "referenced_widgets": [
            "eef7da1fd24545f7b7dee979e646a3f5",
            "8aa9836d9f274803b94931f34fbdb5a1",
            "18d92eec7e4a409e8cf6b05d3445972d",
            "2cf761a67ba247e28a54ee5ae463a847",
            "add2406d2ee5423e8cf5df5acc453b33",
            "d87ddfb514164dfc8b87eddf66dab4a8",
            "6f753a57290b49e1ace3fbca13143a1c",
            "ad77178711b745bb8ad865512e3f8bb6",
            "a5f43b7db0324260a8906571e4fd4ae7",
            "a5c95605762c43369efd9014eecf6015",
            "6183d7d833f94510b3afbbdea0945187",
            "6cac45805ae14b9a958dde655285b374",
            "96f9ec6fb5884ae2998f48383b3b335d",
            "3d5a0d65c82b4f838b32f2c8ee4828f8",
            "ea88884ab90c466bb932d8a6188c850c",
            "93f755210bf34b38989bc0b2841510b1",
            "af5c9c9d50d24dae86d90e9a7c431d8e",
            "cd18d4974dd54b219e43c7e93d904e0d",
            "dd5cabc1a3c145d0867a8d242e686b18",
            "e12c3bc553cf4d238cf33175d1dadf31",
            "6e4d39863e454f1e83448f87c5bbbc66",
            "056be4dd6527493eb4990a46b59e238e",
            "c084baef6de9469cb0a4bf4b967b11c5",
            "28c4474562a04f938d10569b2344f84a",
            "b0a7ac7bc3b540efbfe6f581317601be",
            "a281a6f24c4546f8a97aa6b78865d2d0",
            "d166957e3ff9442a9ce0df3dc1f51b2b",
            "2eb0ec35942245b0b724301d24204699",
            "02f01bc1bca44a24bea86c9784e5a82d",
            "1f7beb8e03fc4481942427547dff92eb",
            "f94c848b51074b8485fc35fe66c61440",
            "b772bb983b3344a587ecf6be04f06dd5"
          ]
        }
      },
      "source": [
        "federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.Pad((2,2,2,2)),\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ]))\n",
        "    .federate(args.workers), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
        "    # .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
        "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                    transforms.Pad((2,2,2,2)),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=args.test_batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "\n",
        "from collections import defaultdict\n",
        "worker_counts = defaultdict(int)\n",
        "worker_data_loader = defaultdict(list)\n",
        "count = 0\n",
        "for batch_idx, (data, target) in enumerate(federated_train_loader): # <-- now it is a distributed dataset\n",
        "    count += 1\n",
        "    worker_counts[data.location.id] += 1\n",
        "    worker_data_loader[data.location.id].append((data, target))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eef7da1fd24545f7b7dee979e646a3f5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5f43b7db0324260a8906571e4fd4ae7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af5c9c9d50d24dae86d90e9a7c431d8e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0a7ac7bc3b540efbfe6f581317601be",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:The following options are not supported: num_workers: 1, pin_memory: True\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmiGcIKAywHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(Net, self).__init__()\n",
        "#         self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "#         self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "#         self.fc1 = nn.Linear(4*4*50, 500)\n",
        "#         self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = F.relu(self.conv1(x))\n",
        "#         x = F.max_pool2d(x, 2, 2)\n",
        "#         x = F.relu(self.conv2(x))\n",
        "#         x = F.max_pool2d(x, 2, 2)\n",
        "#         x = x.view(-1, 4*4*50)\n",
        "#         x = F.relu(self.fc1(x))\n",
        "#         x = self.fc2(x)\n",
        "#         return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "class CNN_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(64, 16, 7, 1)\n",
        "        self.fc1 = nn.Linear(4*4*16, 200)\n",
        "        self.fc2 = nn.Linear(200, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 1, 32, 32)\n",
        "        x = F.tanh(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.tanh(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*16)\n",
        "        x = F.tanh(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "    \n",
        "\n",
        "class MLP_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP_Net, self).__init__()        \n",
        "        self.fc1 = nn.Linear(1024, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1,  1024)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)        \n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS4iRJ1iywNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(args, model, device, federated_train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(federated_train_loader): # <-- now it is a distributed dataset\n",
        "        model.send(data.location) # <-- NEW: send the model to the right location\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        model.get() # <-- NEW: get the model back\n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            loss = loss.get() # <-- NEW: get the loss back\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * args.batch_size, len(federated_train_loader) * args.batch_size,\n",
        "                100. * batch_idx / len(federated_train_loader), loss.item()))\n",
        "\n",
        "def test(args, model, device, test_loader, verbose=True):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    if verbose:\n",
        "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            test_loss, correct, len(test_loader.dataset),\n",
        "            100. * correct / len(test_loader.dataset)))\n",
        "    test_acc = 1.* correct / len(test_loader.dataset)\n",
        "    return test_acc\n",
        "\n",
        "def averge_parameters(redundant_models):\n",
        "    final_model = Net().to(device)\n",
        "    for i, redundant_model in enumerate(redundant_models):\n",
        "        for param_final, param_redundant in zip(final_model.parameters(), redundant_model.parameters()):\n",
        "            if i == 0:\n",
        "                param_final.data = param_redundant.data * 1./ len(redundant_models)\n",
        "            else:\n",
        "                param_final.data += param_redundant.data * 1./ len(redundant_models)\n",
        "    return final_model\n",
        "\n",
        "\n",
        "def add_update_to_model(model, update, weight=1.0):\n",
        "    for param_model, param_update in zip(model.parameters(), update):\n",
        "        param_model.data += weight * param_update.data\n",
        "    return model\n",
        "\n",
        "def compute_grad_update(old_model, new_model):\n",
        "    # maybe later to implement on selected layers/parameters\n",
        "    return [(new_param.data - old_param.data) for old_param, new_param in zip(old_model.parameters(), new_model.parameters())]\n",
        "\n",
        "\n",
        "def add_gradient_updates(grad_update_1, grad_update_2):\n",
        "    assert len(grad_update_1) == len(grad_update_2), \"Lengths of the two grad_updates not equal\"\n",
        "    return [ grad_update_1[i] + grad_update_2[i]  for i in range(len(grad_update_1))]\n",
        "\n",
        "def cosine_similarity(old_grad_update, new_grad_update):    \n",
        "    cos = nn.CosineSimilarity(dim=0)\n",
        "    # flatten the gradient updates and find cos_sim layer-wise and then take average\n",
        "    similarity = 0\n",
        "    for param_update_old, param_update_new in zip(old_grad_update, new_grad_update):\n",
        "        similarity += cos(param_update_old.data.view(-1), param_update_new.data.view(-1))\n",
        "    similarity /= len(old_grad_update) # divide by # layers\n",
        "    return similarity\n",
        "\n",
        "def train_shapley(args, model, device, worker_data_loader, optimizer, epoch, contributions, Max_num_sequences=20):\n",
        "    \n",
        "    workerIds_str = [worker.id for worker in args.workers]\n",
        "    workerIds_int = [int(worker.id) for worker in args.workers]\n",
        "\n",
        "    all_sequences = list(permutations(workerIds_int))\n",
        "    if len(all_sequences) > Max_num_sequences:\n",
        "        random.shuffle(all_sequences)\n",
        "        all_sequences = all_sequences[:Max_num_sequences]\n",
        "\n",
        "    test_acc_prev_epoch = test(args, model, device, test_loader, verbose=False)\n",
        "\n",
        "    model_prev_epoch = copy.deepcopy(model)\n",
        "    model_prev_epoch.load_state_dict(model.state_dict())\n",
        "\n",
        "    # need to deep clone the model before starting the optimizer step and so on\n",
        "    # in principle, there should be M different models/different sets of gradient updates after one epoch\n",
        "    # M being the number of sequences tried\n",
        "\n",
        "    model.train()\n",
        "    # <optional> optimization: for each worker, no longer goes through the entire load: 1. random sampling or 2. organized iteration\n",
        "    grad_updates = [None for _ in workerIds]\n",
        "    # gather all the model updates\n",
        "    for workerId in workerIds_str:\n",
        "        for data, target in worker_data_loader[workerId]:\n",
        "            model.send(data.location) # <-- NEW: send the model to the right location\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = F.nll_loss(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            model.get() # <-- NEW: get the model back\n",
        "        \n",
        "        grad_updates[int(workerId)] = compute_grad_update(model_prev_epoch, model)\n",
        "        model.load_state_dict(model_prev_epoch.state_dict())\n",
        "    print(\"decentralized training complete and all the gradient updates collected\")\n",
        "    # compute the running shapley by evaluating using test acc\n",
        "    update_weight = 1. / len(args.workers)\n",
        "\n",
        "    marginal_contributions = torch.tensor([0.0 for i in workerIds])\n",
        "    leave_one_out_contributions = torch.tensor([0.0 for i  in workerIds])\n",
        "    # coalition_test_acc_dict = {}\n",
        "    for sequence in all_sequences:\n",
        "        curr_contributions = []\n",
        "        sequential_running_model = copy.deepcopy(model_prev_epoch)\n",
        "\n",
        "        # curr_coalition = set()\n",
        "        for i, workerId in enumerate(sequence):\n",
        "            # curr_coalition.add(workerId)\n",
        "            # coalition = tuple(sorted(list(curr_coalition)))\n",
        "            # if coalition in coalition_test_acc_dict:\n",
        "                # test_acc = coalition_test_acc_dict[coalition]\n",
        "            # else:\n",
        "                # test_acc = test(args, sequential_running_model, device, test_loader, verbose=False)\n",
        "                # sequence_test_acc_dict[coalition] = test_acc\n",
        "            sequential_running_model = add_update_to_model(sequential_running_model, grad_updates[workerId], weight=update_weight)\n",
        "            test_acc = test(args, sequential_running_model, device, test_loader, verbose=False)\n",
        "            contribution = test_acc\n",
        "            if not curr_contributions:\n",
        "                marginal_contributions[workerId] += contribution - test_acc_prev_epoch\n",
        "            else:\n",
        "                marginal_contributions[workerId] += contribution - curr_contributions[-1]\n",
        "            \n",
        "                if i == len(sequence)-1 and not leave_one_out_contributions[workerId]:\n",
        "                    leave_one_out_contributions[workerId] = test_acc - curr_contributions[-1]\n",
        "            curr_contributions.append(contribution)\n",
        "\n",
        "        print(curr_contributions)\n",
        "    num_sequences = len(all_sequences)\n",
        "\n",
        "    contributions['shapley'] += marginal_contributions/ num_sequences\n",
        "    contributions['loo'] += leave_one_out_contributions\n",
        "\n",
        "    print(\"Marginal contributions this epoch:\", marginal_contributions/ num_sequences)\n",
        "    print(\"LOO contributions this epoch:\", leave_one_out_contributions)\n",
        "\n",
        "    model.load_state_dict(sequential_running_model.state_dict())\n",
        "\n",
        "    return contributions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R6Qu4J2-WQB",
        "colab_type": "code",
        "outputId": "3aecf50d-8c02-43f7-8145-5cf98b19435f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# try randomly sampling from all the possible sequences\n",
        "# and compute an approximation to the Shapley values\n",
        "# for each sequence, there is a contribution value for all workers involved\n",
        "# and average out all the contribution values for a single worker, across all the sampled sequence to compute this iteration's Shapley Value\n",
        "\n",
        "workerIds = [worker.id for worker in args.workers]\n",
        "\n",
        "model = MLP_Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
        "\n",
        "past_contributions = torch.zeros(np.array(workerIds).shape)\n",
        "loo_contributions = torch.zeros(np.array(workerIds).shape)\n",
        "contributions = {'shapley':past_contributions, 'loo':loo_contributions}\n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    contributions = train_shapley(args, model, device, worker_data_loader, optimizer, epoch, contributions)\n",
        "    test(args, model, device, test_loader)\n",
        "    print(contributions)\n",
        "\n",
        "if (args.save_model):\n",
        "    torch.save(model.state_dict(), \"mnist_mlp.pt\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "decentralized training complete and all the gradient updates collected\n",
            "[0.8872, 0.9116, 0.9124]\n",
            "[0.8872, 0.8953, 0.9124]\n",
            "[0.9196, 0.9116, 0.9124]\n",
            "[0.9196, 0.9187, 0.9124]\n",
            "[0.9036, 0.8953, 0.9124]\n",
            "[0.9036, 0.9187, 0.9124]\n",
            "Marginal contributions this epoch: tensor([0.2548, 0.2826, 0.2665])\n",
            "LOO contributions this epoch: tensor([-0.0063,  0.0171,  0.0008])\n",
            "\n",
            "Test set: Average loss: 0.3952, Accuracy: 9124/10000 (91%)\n",
            "\n",
            "{'shapley': tensor([0.2548, 0.2826, 0.2665]), 'loo': tensor([-0.0063,  0.0171,  0.0008])}\n",
            "decentralized training complete and all the gradient updates collected\n",
            "[0.9387, 0.9517, 0.9572]\n",
            "[0.9387, 0.9501, 0.9572]\n",
            "[0.9399, 0.9517, 0.9572]\n",
            "[0.9399, 0.9516, 0.9572]\n",
            "[0.9377, 0.9501, 0.9572]\n",
            "[0.9377, 0.9516, 0.9572]\n",
            "Marginal contributions this epoch: tensor([0.0147, 0.0160, 0.0141])\n",
            "LOO contributions this epoch: tensor([0.0056, 0.0071, 0.0055])\n",
            "\n",
            "Test set: Average loss: 0.1401, Accuracy: 9572/10000 (96%)\n",
            "\n",
            "{'shapley': tensor([0.2694, 0.2987, 0.2806]), 'loo': tensor([-0.0007,  0.0242,  0.0063])}\n",
            "decentralized training complete and all the gradient updates collected\n",
            "[0.9613, 0.965, 0.9674]\n",
            "[0.9613, 0.9623, 0.9674]\n",
            "[0.9625, 0.965, 0.9674]\n",
            "[0.9625, 0.9655, 0.9674]\n",
            "[0.9618, 0.9623, 0.9674]\n",
            "[0.9618, 0.9655, 0.9674]\n",
            "Marginal contributions this epoch: tensor([0.0025, 0.0047, 0.0030])\n",
            "LOO contributions this epoch: tensor([0.0019, 0.0051, 0.0024])\n",
            "\n",
            "Test set: Average loss: 0.1209, Accuracy: 9674/10000 (97%)\n",
            "\n",
            "{'shapley': tensor([0.2719, 0.3034, 0.2836]), 'loo': tensor([0.0012, 0.0293, 0.0087])}\n",
            "decentralized training complete and all the gradient updates collected\n",
            "[0.9673, 0.9698, 0.9699]\n",
            "[0.9673, 0.9693, 0.9699]\n",
            "[0.9711, 0.9698, 0.9699]\n",
            "[0.9711, 0.9692, 0.9699]\n",
            "[0.9683, 0.9693, 0.9699]\n",
            "[0.9683, 0.9692, 0.9699]\n",
            "Marginal contributions this epoch: tensor([0.0001, 0.0020, 0.0004])\n",
            "LOO contributions this epoch: tensor([7.0000e-04, 6.0000e-04, 1.0000e-04])\n",
            "\n",
            "Test set: Average loss: 0.1103, Accuracy: 9699/10000 (97%)\n",
            "\n",
            "{'shapley': tensor([0.2721, 0.3054, 0.2840]), 'loo': tensor([0.0019, 0.0299, 0.0088])}\n",
            "decentralized training complete and all the gradient updates collected\n",
            "[0.9713, 0.9724, 0.9708]\n",
            "[0.9713, 0.9695, 0.9708]\n",
            "[0.9684, 0.9724, 0.9708]\n",
            "[0.9684, 0.9696, 0.9708]\n",
            "[0.9697, 0.9695, 0.9708]\n",
            "[0.9697, 0.9696, 0.9708]\n",
            "Marginal contributions this epoch: tensor([ 0.0015,  0.0001, -0.0007])\n",
            "LOO contributions this epoch: tensor([ 0.0012,  0.0013, -0.0016])\n",
            "\n",
            "Test set: Average loss: 0.1025, Accuracy: 9708/10000 (97%)\n",
            "\n",
            "{'shapley': tensor([0.2736, 0.3055, 0.2833]), 'loo': tensor([0.0031, 0.0312, 0.0072])}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqpCRTalMxjk",
        "colab_type": "code",
        "outputId": "44385163-3531-47b1-a5f1-e7f24fbad061",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "workerIds = [worker.id for worker in args.workers]\n",
        "\n",
        "model = CNN_Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
        "\n",
        "past_contributions = torch.zeros(np.array(workerIds).shape)\n",
        "loo_contributions = torch.zeros(np.array(workerIds).shape)\n",
        "contributions = {'shapley':past_contributions, 'loo':loo_contributions}\n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    contributions = train_shapley(args, model, device, worker_data_loader, optimizer, epoch, contributions)\n",
        "    test(args, model, device, test_loader)\n",
        "    print(contributions)\n",
        "\n",
        "if (args.save_model):\n",
        "    torch.save(model.state_dict(), \"mnist_mlp.pt\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "decentralized training complete and all the gradient updates collected\n",
            "[0.9435, 0.9444, 0.942]\n",
            "[0.9435, 0.9367, 0.942]\n",
            "[0.9402, 0.9444, 0.942]\n",
            "[0.9402, 0.9453, 0.942]\n",
            "[0.9419, 0.9367, 0.942]\n",
            "[0.9419, 0.9453, 0.942]\n",
            "Marginal contributions this epoch: tensor([0.2925, 0.2952, 0.2921])\n",
            "LOO contributions this epoch: tensor([-0.0033,  0.0053, -0.0024])\n",
            "\n",
            "Test set: Average loss: 0.1748, Accuracy: 9420/10000 (94%)\n",
            "\n",
            "{'shapley': tensor([0.2925, 0.2952, 0.2921]), 'loo': tensor([-0.0033,  0.0053, -0.0024])}\n",
            "decentralized training complete and all the gradient updates collected\n",
            "[0.9667, 0.9753, 0.9805]\n",
            "[0.9667, 0.976, 0.9805]\n",
            "[0.9666, 0.9753, 0.9805]\n",
            "[0.9666, 0.9757, 0.9805]\n",
            "[0.9677, 0.976, 0.9805]\n",
            "[0.9677, 0.9757, 0.9805]\n",
            "Marginal contributions this epoch: tensor([0.0127, 0.0125, 0.0134])\n",
            "LOO contributions this epoch: tensor([0.0048, 0.0045, 0.0052])\n",
            "\n",
            "Test set: Average loss: 0.0633, Accuracy: 9805/10000 (98%)\n",
            "\n",
            "{'shapley': tensor([0.3052, 0.3076, 0.3055]), 'loo': tensor([0.0015, 0.0098, 0.0028])}\n",
            "decentralized training complete and all the gradient updates collected\n",
            "[0.9825, 0.9838, 0.9848]\n",
            "[0.9825, 0.9846, 0.9848]\n",
            "[0.9821, 0.9838, 0.9848]\n",
            "[0.9821, 0.9826, 0.9848]\n",
            "[0.9828, 0.9846, 0.9848]\n",
            "[0.9828, 0.9826, 0.9848]\n",
            "Marginal contributions this epoch: tensor([0.0020, 0.0008, 0.0015])\n",
            "LOO contributions this epoch: tensor([0.0022, 0.0002, 0.0010])\n",
            "\n",
            "Test set: Average loss: 0.0487, Accuracy: 9848/10000 (98%)\n",
            "\n",
            "{'shapley': tensor([0.3072, 0.3084, 0.3070]), 'loo': tensor([0.0037, 0.0100, 0.0038])}\n",
            "decentralized training complete and all the gradient updates collected\n",
            "[0.9862, 0.9864, 0.9861]\n",
            "[0.9862, 0.9853, 0.9861]\n",
            "[0.986, 0.9864, 0.9861]\n",
            "[0.986, 0.9853, 0.9861]\n",
            "[0.9853, 0.9853, 0.9861]\n",
            "[0.9853, 0.9853, 0.9861]\n",
            "Marginal contributions this epoch: tensor([ 0.0008,  0.0007, -0.0002])\n",
            "LOO contributions this epoch: tensor([ 0.0008,  0.0008, -0.0003])\n",
            "\n",
            "Test set: Average loss: 0.0469, Accuracy: 9861/10000 (99%)\n",
            "\n",
            "{'shapley': tensor([0.3080, 0.3091, 0.3068]), 'loo': tensor([0.0045, 0.0108, 0.0035])}\n",
            "decentralized training complete and all the gradient updates collected\n",
            "[0.9876, 0.9876, 0.987]\n",
            "[0.9876, 0.9878, 0.987]\n",
            "[0.9865, 0.9876, 0.987]\n",
            "[0.9865, 0.987, 0.987]\n",
            "[0.9854, 0.9878, 0.987]\n",
            "[0.9854, 0.987, 0.987]\n",
            "Marginal contributions this epoch: tensor([ 0.0011,  0.0001, -0.0003])\n",
            "LOO contributions this epoch: tensor([ 0.0000, -0.0008, -0.0006])\n",
            "\n",
            "Test set: Average loss: 0.0407, Accuracy: 9870/10000 (99%)\n",
            "\n",
            "{'shapley': tensor([0.3090, 0.3092, 0.3065]), 'loo': tensor([0.0045, 0.0100, 0.0029])}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU6pjNVYMxoB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaPLL-bMMxmh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWo8r2f6CSWQ",
        "colab_type": "text"
      },
      "source": [
        "# train shapley that supports both\n",
        "1. shapley train model in each epoch and evaluate based on test acc\n",
        "2. shapley evaluate based on cosine similarity with global historic gradiant update\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72fdXBdcPgYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C1d0K7eCtr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# this train_shapley works for shapley train, NOT federated learning and only on test acc\n",
        "def train_shapley(args, model, device, worker_data_loader, optimizer, epoch, past_contributions, Max_num_sequences=20):\n",
        "    \n",
        "    workerIds = [worker.id for worker in args.workers]\n",
        "    all_sequences = list(permutations(workerIds))\n",
        "    if len(all_sequences) > Max_num_sequences:\n",
        "        random.shuffle(all_sequences)\n",
        "        all_sequences =all_sequences[:Max_num_sequences]\n",
        "\n",
        "    sequence_contribution_dict = {}\n",
        "    test_acc_prev_epoch = test(args, model, device, test_loader, verbose=False)\n",
        "    sequence_contribution_dict['-1'] = test_acc_prev_epoch\n",
        "\n",
        "    model.train()\n",
        "    \n",
        "    # need to deep clone the model before starting the optimizer step and so on\n",
        "    # in principle, there should be M different models/different sets of gradient updates after one epoch\n",
        "    # M being the number of sequences tried\n",
        "    model_prev_epoch = Net().to(device)\n",
        "    model_prev_epoch.load_state_dict(model.state_dict())\n",
        "\n",
        "\n",
        "    # another way of measuring contribution:\n",
        "    # compute a global gradient update history (a up-to-date vector)\n",
        "    # compare the cosine similarity between each individual worker with the global\n",
        "    past_gradient_updates = None\n",
        "    cos = nn.CosineSimilarity()\n",
        "    # flatten the gradient updates and find cos_sim layer-wise and then take average\n",
        "    cos_sim = 0\n",
        "    for param_curr, param_past in zip(model.parameters(), past_model.parameters()):\n",
        "        cos_sim += cos(param_curr.grad.data.view(-1), param_past.grad.data.view(-1))\n",
        "    cos_sim /= len(model.parameters()) # divide by # layers\n",
        "\n",
        "\n",
        "    # <optional> optimization: for each worker, no longer goes through the entire load: 1. random sampling or 2. organized iteration\n",
        "\n",
        "    redundant_models = []\n",
        "    marginal_contributions = torch.tensor([0.0 for i  in workerIds])\n",
        "    for sequence in all_sequences:\n",
        "\n",
        "        curr_contributiuons = []\n",
        "        for workerId in sequence:\n",
        "\n",
        "            for data, target in worker_data_loader[workerId]:\n",
        "                model.send(data.location) # <-- NEW: send the model to the right location\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                output = model(data)\n",
        "                loss = F.nll_loss(output, target)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                model.get() # <-- NEW: get the model back\n",
        "            \n",
        "            test_acc = test(args, model, device, test_loader, verbose=False)\n",
        "            contribution = test_acc\n",
        "            if curr_contributiuons:\n",
        "                marginal_contributions[int(workerId)] += contribution - curr_contributiuons[-1]\n",
        "            else:\n",
        "                marginal_contributions[int(workerId)] += contribution - sequence_contribution_dict['-1']\n",
        "\n",
        "            curr_contributiuons.append(contribution)\n",
        "        assert len(curr_contributiuons) == len(sequence), \"Current contributions not equal to num of workers\"    \n",
        "        sequence_contribution_dict['_'.join(sequence)] = curr_contributiuons\n",
        "\n",
        "        redundant_model = Net().to(device)\n",
        "        redundant_model.load_state_dict(model.state_dict())\n",
        "        redundant_models.append(redundant_model)\n",
        "\n",
        "        model.load_state_dict(model_prev_epoch.state_dict())\n",
        "\n",
        "    num_sequences = len(all_sequences)\n",
        "    past_contributions += marginal_contributions/ num_sequences\n",
        "    print(\"Marginal contributions this epoch:\", marginal_contributions/ num_sequences)\n",
        "\n",
        "    final_model = averge_parameters(redundant_models)\n",
        "    model.load_state_dict(final_model.state_dict())\n",
        "    del final_model\n",
        "    del redundant_models\n",
        "\n",
        "    return past_contributions\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}