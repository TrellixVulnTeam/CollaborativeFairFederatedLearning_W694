Experimental settings are:  {'device': device(type='cpu'), 'dataset': 'adult', 'sample_size_cap': 5000, 'n_workers': 15, 'split': 'power_law', 'sharing_lambda': 0.1, 'batch_size': 16, 'train_val_split_ratio': 0.9, 'model_fn': <class 'utils.models.LogisticRegression'>, 'optimizer_fn': <class 'torch.optim.sgd.SGD'>, 'loss_fn': CrossEntropyLoss(), 'lr': 0.0001, 'pretrain_epochs': 5, 'fl_epochs': 20, 'fl_individual_epochs': 5}
Experiment : No.1/2
reading from datasets/adult.data datasets/adult.test
Start local pretraining 
Performance of an average model of the pretrained local models
Loss: 0.722339. Accuracy: 51.8289%.
Start federated learning 

Epoch 1:
Federated model validation accuracy : 62.2000%
Leave-one-out validation accuracies :  ['62.2000%', '62.4000%', '63.0000%', '63.6000%', '63.6000%', '64.2000%', '66.0000%', '68.0000%', '68.6000%', '69.0000%', '71.2000%', '72.2000%', '72.0000%', '72.4000%', '73.0000%']
Computed and normalized credits:  tensor([0.0765, 0.0761, 0.0748, 0.0736, 0.0736, 0.0725, 0.0690, 0.0653, 0.0642,
        0.0635, 0.0597, 0.0581, 0.0584, 0.0578, 0.0568])
Federated model performance: Loss: 0.650848. Accuracy: 63.8075%.
Workers before    accuracies:  ['50.952%', '51.037%', '51.037%', '51.251%', '51.209%', '51.508%', '51.957%', '51.914%', '51.850%', '52.000%', '51.872%', '52.235%', '52.299%', '52.449%', '52.727%']
Workers standlone accuracies:  ['51.059%', '51.209%', '51.380%', '51.850%', '51.936%', '52.064%', '53.005%', '52.856%', '52.877%', '53.326%', '53.048%', '53.882%', '53.968%', '54.353%', '55.123%']
Workers federated accuracies:  ['51.059%', '51.209%', '51.380%', '51.850%', '51.936%', '52.064%', '53.005%', '52.856%', '52.877%', '53.326%', '53.048%', '53.882%', '53.968%', '54.353%', '55.123%']
Workers improved  accuracies:  ['0.107%', '0.171%', '0.342%', '0.599%', '0.727%', '0.556%', '1.048%', '0.941%', '1.027%', '1.326%', '1.176%', '1.647%', '1.668%', '1.904%', '2.396%']
Workers shard sizes:  [48, 80, 112, 160, 192, 240, 272, 304, 352, 384, 416, 464, 496, 528, 560]

Epoch 2:
Federated model validation accuracy : 69.8000%
Leave-one-out validation accuracies :  ['70.2000%', '70.4000%', '70.8000%', '71.2000%', '71.4000%', '71.8000%', '72.0000%', '72.2000%', '72.8000%', '73.2000%', '73.2000%', '73.8000%', '73.6000%', '73.6000%', '74.6000%']
Computed and normalized credits:  tensor([0.0713, 0.0710, 0.0701, 0.0693, 0.0690, 0.0682, 0.0675, 0.0667, 0.0656,
        0.0648, 0.0644, 0.0632, 0.0636, 0.0635, 0.0618])
Federated model performance: Loss: 0.597757. Accuracy: 69.4545%.
Workers before    accuracies:  ['50.952%', '51.037%', '51.037%', '51.251%', '51.209%', '51.508%', '51.957%', '51.914%', '51.850%', '52.000%', '51.872%', '52.235%', '52.299%', '52.449%', '52.727%']
Workers standlone accuracies:  ['51.273%', '51.529%', '51.722%', '52.299%', '52.342%', '52.920%', '54.182%', '54.118%', '54.075%', '54.631%', '54.332%', '55.743%', '55.529%', '56.193%', '57.412%']
Workers federated accuracies:  ['51.273%', '51.529%', '51.722%', '52.299%', '52.342%', '52.920%', '54.182%', '54.118%', '54.075%', '54.631%', '54.332%', '55.743%', '55.529%', '56.193%', '57.412%']
Workers improved  accuracies:  ['0.321%', '0.492%', '0.684%', '1.048%', '1.134%', '1.412%', '2.225%', '2.203%', '2.225%', '2.631%', '2.460%', '3.508%', '3.230%', '3.743%', '4.684%']
Workers shard sizes:  [48, 80, 112, 160, 192, 240, 272, 304, 352, 384, 416, 464, 496, 528, 560]

Epoch 3:
Federated model validation accuracy : 73.2000%
Leave-one-out validation accuracies :  ['73.2000%', '73.2000%', '73.0000%', '73.2000%', '73.6000%', '73.8000%', '73.8000%', '73.8000%', '74.0000%', '74.2000%', '75.0000%', '75.4000%', '76.0000%', '76.4000%', '76.6000%']
Computed and normalized credits:  tensor([0.0690, 0.0689, 0.0691, 0.0687, 0.0681, 0.0677, 0.0676, 0.0675, 0.0670,
        0.0667, 0.0654, 0.0646, 0.0638, 0.0632, 0.0627])
Federated model performance: Loss: 0.559969. Accuracy: 71.8503%.
Workers before    accuracies:  ['50.952%', '51.037%', '51.037%', '51.251%', '51.209%', '51.508%', '51.957%', '51.914%', '51.850%', '52.000%', '51.872%', '52.235%', '52.299%', '52.449%', '52.727%']
Workers standlone accuracies:  ['51.529%', '51.722%', '52.086%', '52.963%', '52.984%', '53.690%', '55.273%', '55.444%', '55.380%', '56.086%', '55.465%', '57.540%', '57.283%', '58.267%', '59.765%']
Workers federated accuracies:  ['51.529%', '51.722%', '52.086%', '52.963%', '52.984%', '53.690%', '55.273%', '55.444%', '55.380%', '56.086%', '55.465%', '57.540%', '57.283%', '58.267%', '59.765%']
Workers improved  accuracies:  ['0.578%', '0.684%', '1.048%', '1.711%', '1.775%', '2.182%', '3.316%', '3.529%', '3.529%', '4.086%', '3.594%', '5.305%', '4.984%', '5.818%', '7.037%']
Workers shard sizes:  [48, 80, 112, 160, 192, 240, 272, 304, 352, 384, 416, 464, 496, 528, 560]

Epoch 4:
Federated model validation accuracy : 75.0000%
Leave-one-out validation accuracies :  ['75.0000%', '75.0000%', '75.2000%', '75.4000%', '75.4000%', '75.6000%', '75.8000%', '76.0000%', '76.0000%', '76.0000%', '76.0000%', '76.2000%', '76.4000%', '76.6000%', '76.8000%']
Computed and normalized credits:  tensor([0.0682, 0.0682, 0.0679, 0.0675, 0.0675, 0.0671, 0.0668, 0.0665, 0.0665,
        0.0664, 0.0663, 0.0659, 0.0655, 0.0651, 0.0648])
Federated model performance: Loss: 0.534867. Accuracy: 73.1765%.
Workers before    accuracies:  ['50.952%', '51.037%', '51.037%', '51.251%', '51.209%', '51.508%', '51.957%', '51.914%', '51.850%', '52.000%', '51.872%', '52.235%', '52.299%', '52.449%', '52.727%']
Workers standlone accuracies:  ['51.722%', '51.893%', '52.471%', '53.497%', '53.711%', '54.652%', '56.364%', '56.406%', '56.449%', '57.604%', '57.091%', '59.294%', '59.016%', '60.257%', '61.775%']
Workers federated accuracies:  ['51.722%', '51.893%', '52.471%', '53.497%', '53.711%', '54.652%', '56.364%', '56.406%', '56.449%', '57.604%', '57.091%', '59.294%', '59.016%', '60.257%', '61.775%']
Workers improved  accuracies:  ['0.770%', '0.856%', '1.433%', '2.246%', '2.503%', '3.144%', '4.406%', '4.492%', '4.599%', '5.604%', '5.219%', '7.059%', '6.717%', '7.807%', '9.048%']
Workers shard sizes:  [48, 80, 112, 160, 192, 240, 272, 304, 352, 384, 416, 464, 496, 528, 560]

Epoch 5:
Federated model validation accuracy : 76.2000%
Leave-one-out validation accuracies :  ['76.2000%', '76.0000%', '76.0000%', '76.0000%', '76.4000%', '76.6000%', '76.8000%', '76.8000%', '76.8000%', '77.0000%', '77.2000%', '77.4000%', '77.4000%', '77.4000%', '77.6000%']
Computed and normalized credits:  tensor([0.0677, 0.0680, 0.0679, 0.0679, 0.0673, 0.0670, 0.0666, 0.0666, 0.0666,
        0.0663, 0.0660, 0.0657, 0.0656, 0.0656, 0.0652])
Federated model performance: Loss: 0.519603. Accuracy: 73.8824%.
Workers before    accuracies:  ['50.952%', '51.037%', '51.037%', '51.251%', '51.209%', '51.508%', '51.957%', '51.914%', '51.850%', '52.000%', '51.872%', '52.235%', '52.299%', '52.449%', '52.727%']
Workers standlone accuracies:  ['51.957%', '52.321%', '52.770%', '54.182%', '54.289%', '55.465%', '57.754%', '57.754%', '57.626%', '59.102%', '58.717%', '60.642%', '60.834%', '62.011%', '63.401%']
Workers federated accuracies:  ['51.957%', '52.321%', '52.770%', '54.182%', '54.289%', '55.465%', '57.754%', '57.754%', '57.626%', '59.102%', '58.717%', '60.642%', '60.834%', '62.011%', '63.401%']
Workers improved  accuracies:  ['1.005%', '1.283%', '1.733%', '2.930%', '3.080%', '3.957%', '5.797%', '5.840%', '5.775%', '7.102%', '6.845%', '8.406%', '8.535%', '9.561%', '10.674%']
Workers shard sizes:  [48, 80, 112, 160, 192, 240, 272, 304, 352, 384, 416, 464, 496, 528, 560]

Epoch 6:
Federated model validation accuracy : 77.2000%
Leave-one-out validation accuracies :  ['77.4000%', '77.0000%', '76.8000%', '77.0000%', '77.2000%', '77.2000%', '77.0000%', '77.2000%', '77.2000%', '77.2000%', '77.2000%', '77.8000%', '77.8000%', '78.0000%', '78.2000%']
Computed and normalized credits:  tensor([0.0667, 0.0673, 0.0676, 0.0673, 0.0670, 0.0669, 0.0672, 0.0669, 0.0669,
        0.0668, 0.0668, 0.0659, 0.0659, 0.0656, 0.0653])
Federated model performance: Loss: 0.511762. Accuracy: 74.1390%.
Workers before    accuracies:  ['50.952%', '51.037%', '51.037%', '51.251%', '51.209%', '51.508%', '51.957%', '51.914%', '51.850%', '52.000%', '51.872%', '52.235%', '52.299%', '52.449%', '52.727%']