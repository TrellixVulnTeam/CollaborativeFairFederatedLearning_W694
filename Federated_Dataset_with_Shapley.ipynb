{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Tags",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Federated Dataset with Shapley.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XinyiYS/FairAndPrivateFederatedLearning/blob/master/Federated_Dataset_with_Shapley.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_V6KLvuauea_",
        "colab_type": "text"
      },
      "source": [
        "# Federated Dataset with Shapley.ipynb\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osxkFljzvBDW",
        "colab_type": "code",
        "outputId": "fbe42762-7db1-4c93-f35e-af851fd2afbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install 'syft[udacity]'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: syft[udacity] in /usr/local/lib/python3.6/dist-packages (0.2.4)\n",
            "Requirement already satisfied: tornado==4.5.3 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (4.5.3)\n",
            "Requirement already satisfied: syft-proto~=0.2.5.a1 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (0.2.5a1)\n",
            "Requirement already satisfied: msgpack~=1.0.0 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (1.0.0)\n",
            "Requirement already satisfied: websocket-client~=0.57.0 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (0.57.0)\n",
            "Requirement already satisfied: Pillow~=6.2.2 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (6.2.2)\n",
            "Requirement already satisfied: requests~=2.22.0 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (2.22.0)\n",
            "Requirement already satisfied: websockets~=8.1.0 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (8.1)\n",
            "Requirement already satisfied: numpy~=1.18.1 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (1.18.2)\n",
            "Requirement already satisfied: flask-socketio~=4.2.1 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (4.2.1)\n",
            "Requirement already satisfied: phe~=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (1.4.0)\n",
            "Requirement already satisfied: Flask~=1.1.1 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (1.1.1)\n",
            "Requirement already satisfied: torchvision~=0.5.0 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (0.5.0)\n",
            "Requirement already satisfied: lz4~=3.0.2 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (3.0.2)\n",
            "Requirement already satisfied: scipy~=1.4.1 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (1.4.1)\n",
            "Requirement already satisfied: torch~=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (1.4.0)\n",
            "Requirement already satisfied: tblib~=1.6.0 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (1.6.0)\n",
            "Requirement already satisfied: tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\" in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (0.5.9)\n",
            "Requirement already satisfied: protobuf>=3.11.1 in /usr/local/lib/python3.6/dist-packages (from syft-proto~=0.2.5.a1->syft[udacity]) (3.11.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from websocket-client~=0.57.0->syft[udacity]) (1.12.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests~=2.22.0->syft[udacity]) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests~=2.22.0->syft[udacity]) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests~=2.22.0->syft[udacity]) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests~=2.22.0->syft[udacity]) (2019.11.28)\n",
            "Requirement already satisfied: python-socketio>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from flask-socketio~=4.2.1->syft[udacity]) (4.5.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask~=1.1.1->syft[udacity]) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask~=1.1.1->syft[udacity]) (2.11.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask~=1.1.1->syft[udacity]) (7.1.1)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask~=1.1.1->syft[udacity]) (1.0.1)\n",
            "Collecting tensorflow<2,>=1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/d9/fd234c7bf68638423fb8e7f44af7fcfce3bcaf416b51e6d902391e47ec43/tensorflow-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (110.5MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5MB 56kB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (5.3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.11.1->syft-proto~=0.2.5.a1->syft[udacity]) (46.0.0)\n",
            "Requirement already satisfied: python-engineio>=3.9.0 in /usr/local/lib/python3.6/dist-packages (from python-socketio>=4.3.0->flask-socketio~=4.2.1->syft[udacity]) (3.12.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask~=1.1.1->syft[udacity]) (1.1.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (0.9.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (1.0.8)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (0.34.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (1.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (0.2.2)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 29.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (3.2.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 59.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (1.27.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (3.2.1)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.2.0\n",
            "    Uninstalling tensorboard-2.2.0:\n",
            "      Successfully uninstalled tensorboard-2.2.0\n",
            "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
            "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
            "  Found existing installation: tensorflow 2.2.0rc2\n",
            "    Uninstalling tensorflow-2.2.0rc2:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc2\n",
            "Successfully installed tensorboard-1.15.0 tensorflow-1.15.2 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_core",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpsepMYvATV7",
        "colab_type": "code",
        "outputId": "a0d7dbdd-2b22-49b7-8e96-8156d44a4739",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLB-g-bPuebB",
        "colab_type": "code",
        "outputId": "283854c9-ae9b-46f5-e528-2a82e90df4f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "import random\n",
        "from itertools import permutations\n",
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import syft as sy  # <-- NEW: import the Pysyft library\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.2.so'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN73GJ-eybxh",
        "colab_type": "code",
        "outputId": "45d80bfe-47d4-405d-b11b-85cb269b56d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 64 #@param\n",
        "        self.test_batch_size = 1000 #@param\n",
        "        self.epochs = epochs\n",
        "        self.lr = 0.01 #@param\n",
        "        self.momentum = 0.5\n",
        "        self.no_cuda = False\n",
        "        self.seed = 1\n",
        "        self.log_interval = 150 #@param\n",
        "        self.save_model = False\n",
        "\n",
        "epochs = 15 #@param\n",
        "\n",
        "args = Arguments()\n",
        "\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "\n",
        "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
        "\n",
        "num_workers = 3#@param\n",
        "\n",
        "workers = [ sy.VirtualWorker(hook, id=str(i)) for i in range(num_workers) ]\n",
        "workerIds = [worker.id for worker in workers]\n",
        "\n",
        "# bob = sy.VirtualWorker(hook, id=\"bob\")  # <-- NEW: define remote worker bob\n",
        "# alice = sy.VirtualWorker(hook, id=\"alice\")  # <-- NEW: and alice"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Torch was already hooked... skipping hooking process\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg2C19D6ywFY",
        "colab_type": "code",
        "outputId": "47f6002e-ec73-4b3f-b5dd-d8d642a5c0c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ]))\n",
        "    .federate(workers), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
        "    # .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
        "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=args.test_batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "\n",
        "from collections import defaultdict\n",
        "worker_counts = defaultdict(int)\n",
        "worker_data_loader = defaultdict(list)\n",
        "count = 0\n",
        "for batch_idx, (data, target) in enumerate(federated_train_loader): # <-- now it is a distributed dataset\n",
        "    count += 1\n",
        "    worker_counts[data.location.id] += 1\n",
        "    worker_data_loader[data.location.id].append((data, target))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:The following options are not supported: num_workers: 1, pin_memory: True\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmiGcIKAywHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS4iRJ1iywNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(args, model, device, federated_train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(federated_train_loader): # <-- now it is a distributed dataset\n",
        "        model.send(data.location) # <-- NEW: send the model to the right location\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        model.get() # <-- NEW: get the model back\n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            loss = loss.get() # <-- NEW: get the loss back\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * args.batch_size, len(federated_train_loader) * args.batch_size,\n",
        "                100. * batch_idx / len(federated_train_loader), loss.item()))\n",
        "\n",
        "def test(args, model, device, test_loader, verbose=True):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    if verbose:\n",
        "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            test_loss, correct, len(test_loader.dataset),\n",
        "            100. * correct / len(test_loader.dataset)))\n",
        "    test_acc = 1.* correct / len(test_loader.dataset)\n",
        "    return test_acc\n",
        "\n",
        "def averge_parameters(redundant_models):\n",
        "    final_model = Net().to(device)\n",
        "    for i, redundant_model in enumerate(redundant_models):\n",
        "        for param_final, param_redundant in zip(final_model.parameters(), redundant_model.parameters()):\n",
        "            if i == 0:\n",
        "                param_final.data = param_redundant.data * 1./ len(redundant_models)\n",
        "            else:\n",
        "                param_final.data += param_redundant.data * 1./ len(redundant_models)\n",
        "    return final_model\n",
        "\n",
        "def train_shapley(args, model, device, worker_data_loader, optimizer, epoch, past_contributions):\n",
        "    \n",
        "    all_sequences = list(permutations(workerIds))\n",
        "    random.shuffle(all_sequences)\n",
        "    sequence_contribution_dict = {}\n",
        "    test_acc_prev_epoch = test(args, model, device, test_loader, verbose=False)\n",
        "    sequence_contribution_dict['-1'] = test_acc_prev_epoch\n",
        "\n",
        "    model.train()\n",
        "    \n",
        "    # need to deep clone the model before starting the optimizer step and so on\n",
        "    # in principle, there should be M different models/different sets of gradient updates after one epoch\n",
        "    # M being the number of sequences tried\n",
        "    model_prev_epoch = Net().to(device)\n",
        "    model_prev_epoch.load_state_dict(model.state_dict())\n",
        "\n",
        "\n",
        "    # another way of measuring contribution:\n",
        "    # compute a global gradient update history (a up-to-date vector)\n",
        "    # compare the cosine similarity between each individual worker with the global\n",
        "    \n",
        "\n",
        "    # for optimization: for each worker, no longer goes through the entire load: 1. random sampling or 2. organized iteration\n",
        "\n",
        "    redundant_models = []\n",
        "    marginal_contributions = torch.tensor([0.0 for i  in workerIds])\n",
        "    for sequence in all_sequences:\n",
        "\n",
        "        curr_contributiuons = []\n",
        "        for workerId in sequence:\n",
        "\n",
        "            for data, target in worker_data_loader[workerId]:\n",
        "                model.send(data.location) # <-- NEW: send the model to the right location\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                output = model(data)\n",
        "                loss = F.nll_loss(output, target)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                model.get() # <-- NEW: get the model back\n",
        "            \n",
        "            test_acc = test(args, model, device, test_loader, verbose=False)\n",
        "            contribution = test_acc\n",
        "            if curr_contributiuons:\n",
        "                marginal_contributions[int(workerId)] += contribution - curr_contributiuons[-1]\n",
        "            else:\n",
        "                marginal_contributions[int(workerId)] += contribution - sequence_contribution_dict['-1']\n",
        "\n",
        "            curr_contributiuons.append(contribution)\n",
        "        assert len(curr_contributiuons) == len(sequence), \"Current contributions not equal to num of workers\"    \n",
        "        sequence_contribution_dict['_'.join(sequence)] = curr_contributiuons\n",
        "\n",
        "        redundant_model = Net().to(device)\n",
        "        redundant_model.load_state_dict(model.state_dict())\n",
        "        redundant_models.append(redundant_model)\n",
        "\n",
        "        model.load_state_dict(model_prev_epoch.state_dict())\n",
        "\n",
        "    num_sequences = len(all_sequences)\n",
        "    past_contributions += marginal_contributions/ num_sequences\n",
        "    print(\"Marginal contributions this epoch:\", marginal_contributions/ num_sequences)\n",
        "\n",
        "    final_model = averge_parameters(redundant_models)\n",
        "    model.load_state_dict(final_model.state_dict())\n",
        "    del final_model\n",
        "    del redundant_models\n",
        "\n",
        "    return past_contributions\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R6Qu4J2-WQB",
        "colab_type": "code",
        "outputId": "9f3fc87b-309a-4af8-849d-ad5f17447281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 943
        }
      },
      "source": [
        "# try randomly sampling from all the possible sequences\n",
        "# and compute an approximation to the Shapley values\n",
        "# for each sequence, there is a contribution value for all workers involved\n",
        "# and average out all the contribution values for a single worker, across all the sampled sequence to compute this iteration's Shapley Value\n",
        "\n",
        "workerIds = [worker.id for worker in workers]\n",
        "\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
        "past_contributions = torch.tensor([0.0 for i  in workerIds])\n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    past_contributions = train_shapley(args, model, device, worker_data_loader, optimizer, epoch, past_contributions)\n",
        "    test(args, model, device, test_loader)\n",
        "    print(past_contributions)\n",
        "\n",
        "if (args.save_model):\n",
        "    torch.save(model.state_dict(), \"mnist_cnn.pt\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Marginal contributions this epoch: tensor([0.2584, 0.3046, 0.2923])\n",
            "\n",
            "Test set: Average loss: 0.1528, Accuracy: 9567/10000 (96%)\n",
            "\n",
            "tensor([0.2584, 0.3046, 0.2923])\n",
            "Marginal contributions this epoch: tensor([0.0052, 0.0020, 0.0067])\n",
            "\n",
            "Test set: Average loss: 0.0873, Accuracy: 9739/10000 (97%)\n",
            "\n",
            "tensor([0.2636, 0.3067, 0.2990])\n",
            "Marginal contributions this epoch: tensor([ 0.0046, -0.0022,  0.0006])\n",
            "\n",
            "Test set: Average loss: 0.0657, Accuracy: 9802/10000 (98%)\n",
            "\n",
            "tensor([0.2682, 0.3044, 0.2996])\n",
            "Marginal contributions this epoch: tensor([ 0.0031, -0.0036, -0.0003])\n",
            "\n",
            "Test set: Average loss: 0.0550, Accuracy: 9827/10000 (98%)\n",
            "\n",
            "tensor([0.2714, 0.3008, 0.2993])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f9be7e05860>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 930, in _shutdown_workers\n",
            "    self._worker_result_queue.close()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 134, in close\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "    self._reader.close()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 177, in close\n",
            "    self._close()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 361, in _close\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "    _close(self._handle)\n",
            "OSError: [Errno 9] Bad file descriptor\n",
            "Traceback (most recent call last):\n",
            "OSError: [Errno 9] Bad file descriptor\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 230, in _feed\n",
            "    close()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 177, in close\n",
            "    self._close()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 361, in _close\n",
            "    _close(self._handle)\n",
            "OSError: [Errno 9] Bad file descriptor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIKvYfky833E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "past_contributions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od4N8FafZ3ZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}